{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2-B5UZxUchfd"
   },
   "source": [
    "# Análisis de MNIST con eager execution, tf.keras y tf.data\n",
    "\n",
    "**Profesor:** Roberto Muñoz <br />\n",
    "**E-mail:** <rmunoz@metricarts.com> <br />\n",
    "\n",
    "**Profesor:** Sebastián Arpón <br />\n",
    "**E-mail:** <rmunoz@metricarts.com> <br />\n",
    "\n",
    "En este laboratorio crearemos una red neuronal que pueda detectar a que digito corresponde una imagen que recibe (note que cada imagen contendra solo un digito). Utilizaremos la API `tf.data` [Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) la cual es muy eficiente e incluye funcionalidades como el shuffling y batching. \n",
    "\n",
    "El conjunto de datos con el que trabajaremos es el MINST el cual, como veremos mas adelante esta incluido en KERAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "902Rjd5DZroO"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Activando Eager\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usamos la API de keras para descargar el dataset de MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "evWlYUkYefG8"
   },
   "outputs": [],
   "source": [
    "# obteniendo la data\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño train dataset:  60000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Tamaño train dataset: \", len(train_labels))\n",
    "\n",
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño test dataset:  10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Tamaño test dataset: \", len(test_labels))\n",
    "\n",
    "np.unique(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisamos el tamaño de train_images y train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images\n",
      "Tipo:  <class 'numpy.ndarray'>\n",
      "Nº de elementos:  60000\n",
      "Dimensiones:  (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train images\")\n",
    "print(\"Tipo: \", type(train_images))\n",
    "print(\"Nº de elementos: \", len(train_images))\n",
    "print(\"Dimensiones: \", train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels\n",
      "Tipo:  <class 'numpy.ndarray'>\n",
      "Nº de elementos:  60000\n",
      "Dimensiones:  (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train labels\")\n",
    "print(\"Tipo: \", type(train_labels))\n",
    "print(\"Nº de elementos: \", len(train_labels))\n",
    "print(\"Dimensiones: \", train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12c4b27f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[4,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisamos un par de imágenes del dataset train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indice del registro:  13056\n",
      "Label:  7\n",
      "Tamaño en pixels:  (28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb361e4198>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i=np.random.randint(len(train_images))\n",
    "\n",
    "print(\"Indice del registro: \", i)\n",
    "print(\"Label: \", train_labels[i])\n",
    "print(\"Tamaño en pixels: \", train_images[i].shape)\n",
    "plt.imshow(train_images[i,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformamos train_images y test_images\n",
    "\n",
    "Transformamos train_images y test_images de matrices de 28x28 a un vector de largo 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JA3braIeeggc"
   },
   "outputs": [],
   "source": [
    "# Chequeando el tamaño de los conjuntos de entrenamiento y test\n",
    "TRAINING_SIZE = len(train_images)\n",
    "TEST_SIZE = len(test_images)\n",
    "\n",
    "# transformando desde (N, 28, 28) a (N, 784)\n",
    "train_images = np.reshape(train_images, (TRAINING_SIZE, 784))\n",
    "test_images = np.reshape(test_images, (TEST_SIZE, 784))\n",
    "\n",
    "# Transformando cada arreglo desde uint8 a float32\n",
    "train_images = train_images.astype(np.float32)\n",
    "test_images = test_images.astype(np.float32)\n",
    "\n",
    "# Convirtiendo cada valor desde [0,255] a [0,1] \n",
    "train_images /= 255\n",
    "test_images /=  255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images\n",
      "60000\n",
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train images\")\n",
    "print(len(train_images))\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images\n",
      "10000\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test images\")\n",
    "print(len(test_images))\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformamos las etiquetas en un vector \n",
    "\n",
    "Usamos la función **tf.keras.utils.to_categorical** del módulo **tf.keras** para transformar cada valor de etiqueta a un vector conformato categórico.\n",
    "\n",
    "En el caso de usar la función de costo **categorical_crossentropy**, las etiquetas deben ser transformadas en formato categórico. Si tenemos 10 clases, entonces cada etiqueta debe ser transformado en un vector de largo 10 donde **todos los valores son cero** excepto el índice correspondiente a la clase el cual tendrá el **valor uno**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'train_labels_ORIG' not in locals():\n",
    "    train_labels_ORIG=train_labels.copy()\n",
    "    \n",
    "if 'test_labels_ORIG' not in locals():\n",
    "    test_labels_ORIG=test_labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wbwRqi0BeicT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previo al cambio de formato\t:  5\n",
      "Posterior al cambio de formato\t:  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "NUM_DIGITS = 10\n",
    "\n",
    "train_labels  = tf.keras.utils.to_categorical(train_labels_ORIG, NUM_DIGITS)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels_ORIG, NUM_DIGITS)\n",
    "\n",
    "print(\"Previo al cambio de formato\\t: \", train_labels_ORIG[0]) # The format of the labels before conversion\n",
    "print(\"Posterior al cambio de formato\\t: \", train_labels[0]) # The format of the labels after conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(type(train_labels))\n",
    "print(train_labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = train_labels.astype(np.float32)\n",
    "test_labels = test_labels.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(type(train_labels))\n",
    "print(train_labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definimos la arquitectura de la red neuronal con Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jjNr3gr3ejh2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/rmunoz/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(300, activation=tf.nn.relu, input_shape=(784,)))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definimos el optimizador que usaremos\n",
    "\n",
    "Esto es obligatorio mientras usamos eager execution\n",
    "\n",
    "Usaremos el optimizador RMS Propagation\n",
    "\n",
    "Más info en https://www.tensorflow.org/api_guides/python/train#Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001)\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elegimos la función de costo y compilamos el modelo\n",
    "\n",
    "Usaremos la función de costo categorical_crossentropy\n",
    "\n",
    "Más info de losses en https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
    "\n",
    "Más info de metrics en https://www.tensorflow.org/api_docs/python/tf/keras/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 238,510\n",
      "Trainable params: 238,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUZPvDQYe5Xu"
   },
   "source": [
    "## 1. Entrenamos el modelo usando tf.data y train_on_batch()\n",
    "\n",
    "### Paso 1 - Creamos un dataset del tipo tf.data\n",
    "\n",
    "Ahora usaremos `tf.data.Dataset` [API](https://www.tensorflow.org/api_docs/python/tf/data) para convertir los arreglos de Numpy en un dataset de TensorFlow\n",
    "\n",
    "A continuacion crearemos un ciclo **for** que servira como una introduccion en la creacion de ciclos de entrenamientos personalizados. Aunque esencialmente estos ciclos hacer lo mismo que `model.fit`, esto nos permite personalizar todo el proceso y recolectar distintas metricas.\n",
    "\n",
    "Usamos un batch size de 128 elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "sdBd2pd_fdue"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n",
    "\n",
    "# Dado que tf.data puede funcionar en colecciones de datos potencialmente grandes\n",
    "# La desordenaremos por partes.\n",
    "SHUFFLE_SIZE = 10000 \n",
    "\n",
    "# Creando el dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "dataset = dataset.shuffle(SHUFFLE_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ksAR-C6xgUu4"
   },
   "source": [
    "### Step 2 - Definimos las epocas de entrenamiento y entrenamos\n",
    "\n",
    "Aca entrenaremos sobre el dataset usando los distintos batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kNgnUKPvgSCz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/rmunoz/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch #1\t Loss: 0.163656\tAccuracy: 0.916667\n",
      "Epoch #2\t Loss: 0.060673\tAccuracy: 0.979167\n",
      "Epoch #3\t Loss: 0.136471\tAccuracy: 0.979167\n",
      "Epoch #4\t Loss: 0.068292\tAccuracy: 0.979167\n",
      "Epoch #5\t Loss: 0.103397\tAccuracy: 0.979167\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for images, labels in dataset:\n",
    "        train_loss, train_accuracy = model.train_on_batch(images, labels)\n",
    "  \n",
    "  # Obtenemos cualquier metrica o ajustamos los parametros de entrenamiento\n",
    "    print('Epoch #%d\\t Loss: %.6f\\tAccuracy: %.6f' % (epoch + 1, train_loss, train_accuracy))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tg5U3Iqkgo3J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 59us/sample - loss: 0.0720 - acc: 0.9783\n",
      "Test accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy: %.2f' % (accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Entrenamos el modelo usando fit()\n",
    "\n",
    "### Paso 1 - Creamos una función que define el modelo\n",
    "\n",
    "Usaremos **sparse_categorical_crossentropy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/rmunoz/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Returns a short sequential model\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(784,)))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.8))\n",
    "    model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "  \n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "                  loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                  metrics=['accuracy'])\n",
    "  \n",
    "    return model\n",
    "\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2 - Entrenamos el modelo usando fit()\n",
    "\n",
    "Dado que usaremos la función de costo **tf.keras.losses.sparse_categorical_crossentropy**, las etiquetas deben ser valores simples y no vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = train_labels_ORIG.copy()\n",
    "test_labels = test_labels_ORIG.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS=5\n",
    "checkpoint_dir = \"results\"\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.mkdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "59872/60000 [============================>.] - ETA: 0s - loss: 0.4364 - acc: 0.8655\n",
      "Epoch 00001: saving model to results/model_mnist_0001.ckpt\n",
      "WARNING:tensorflow:From /Users/rmunoz/anaconda3/envs/deep_learning/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "60000/60000 [==============================] - 11s 191us/sample - loss: 0.4361 - acc: 0.8656 - val_loss: 0.1668 - val_acc: 0.9503\n",
      "Epoch 2/5\n",
      "59872/60000 [============================>.] - ETA: 0s - loss: 0.2712 - acc: 0.9164\n",
      "Epoch 00002: saving model to results/model_mnist_0002.ckpt\n",
      "60000/60000 [==============================] - 12s 207us/sample - loss: 0.2712 - acc: 0.9165 - val_loss: 0.1291 - val_acc: 0.9621\n",
      "Epoch 3/5\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 0.2402 - acc: 0.9268\n",
      "Epoch 00003: saving model to results/model_mnist_0003.ckpt\n",
      "60000/60000 [==============================] - 13s 211us/sample - loss: 0.2403 - acc: 0.9268 - val_loss: 0.1121 - val_acc: 0.9658\n",
      "Epoch 4/5\n",
      "59936/60000 [============================>.] - ETA: 0s - loss: 0.2179 - acc: 0.9348\n",
      "Epoch 00004: saving model to results/model_mnist_0004.ckpt\n",
      "60000/60000 [==============================] - 13s 221us/sample - loss: 0.2178 - acc: 0.9348 - val_loss: 0.1024 - val_acc: 0.9687\n",
      "Epoch 5/5\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2024 - acc: 0.9391\n",
      "Epoch 00005: saving model to results/model_mnist_0005.ckpt\n",
      "60000/60000 [==============================] - 12s 201us/sample - loss: 0.2022 - acc: 0.9391 - val_loss: 0.0999 - val_acc: 0.9702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb428ad9e8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = os.path.join(checkpoint_dir, \"model_mnist_{epoch:04d}.ckpt\")\n",
    "\n",
    "# Create checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                checkpoint_path, verbose=1, save_weights_only=True,\n",
    "                # Save weights, every 1-epochs\n",
    "                period=1)\n",
    "                                                 \n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.fit(train_images, train_labels,  epochs = EPOCHS, \n",
    "          validation_data = (test_images, test_labels),\n",
    "          callbacks = [cp_callback])  # pass callback to training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluamos el modelo recién entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 68us/sample - loss: 0.0999 - acc: 0.9702\n",
      "Model accuracy: 97.02%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(\"Model accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restauramos una época del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/model_mnist_0001.ckpt.data-00000-of-00001\n",
      "results/model_mnist_0002.ckpt.data-00000-of-00001\n",
      "results/model_mnist_0003.ckpt.data-00000-of-00001\n",
      "results/model_mnist_0004.ckpt.data-00000-of-00001\n",
      "results/model_mnist_0005.ckpt.data-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "pattern = os.path.join(checkpoint_dir, \"*.ckpt.data*\")\n",
    "checkpoints = sorted(glob.glob(pattern))\n",
    "\n",
    "for file in checkpoints:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 67us/sample - loss: 0.0999 - acc: 0.9702\n",
      "Restored model - accuracy: 97.02%\n"
     ]
    }
   ],
   "source": [
    "weight_file = 'results/model_mnist_0005.ckpt'\n",
    "\n",
    "model = create_model()\n",
    "model.load_weights(weight_file)\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(\"Restored model - accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "2-mnist-with-keras-eager-and-tf-data.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Deep Learning",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
